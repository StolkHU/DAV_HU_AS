{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from loguru import logger\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomllib\n",
    "\n",
    "configfile = Path(\"../config.toml\").resolve()\n",
    "with configfile.open(\"rb\") as f:\n",
    "    config = tomllib.load(f)\n",
    "datafile = (Path(\"..\") / Path(config[\"processed\"]) / config[\"current\"]).resolve()\n",
    "if not datafile.exists():\n",
    "    logger.warning(\n",
    "        \"Datafile does not exist. First run src/preprocess.py, and check the timestamp!\"\n",
    "    )\n",
    "wa_df = pd.read_parquet(datafile)\n",
    "# wa_df = wa_df.groupby('author').filter(lambda x: len(x) > 50)\n",
    "\n",
    "author_message_count = wa_df['author'].value_counts()\n",
    "# print(author_message_count)\n",
    "distinct_authors_count = wa_df['author'].nunique()\n",
    "print(distinct_authors_count)\n",
    "\n",
    "wa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"..\").resolve()\n",
    "processed = root / Path(config[\"processed\"])\n",
    "raw = root / Path(config[\"raw\"])\n",
    "datafile = processed / config[\"current\"]\n",
    "role_file = raw / config[\"role_file\"]\n",
    "player_roles = pd.read_json(role_file, encoding = \"latin\")\n",
    "player_roles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_roles = pd.read_json(role_file, encoding = \"latin\")\n",
    "player_roles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(wa_df, player_roles, left_on='author', right_on='Author')\n",
    "merged_df = merged_df.drop(columns=['Author'])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = list(np.unique(wa_df.author))\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = list(np.unique(merged_df.Position))\n",
    "print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "min_parts = 2\n",
    "\n",
    "corpus = {}\n",
    "for author in authors:\n",
    "    subset = wa_df[wa_df.author == author].reset_index()\n",
    "    longseq = \" \".join(subset.message)\n",
    "    # chunk everything into n-sized parts\n",
    "    parts = [longseq[i : i + n] for i in range(0, len(longseq), n)]\n",
    "    # keep only parts with more than min_parts\n",
    "    if len(parts) > min_parts:\n",
    "        corpus[author] = parts\n",
    "corpus.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wa_analysis.data_analysis.model import TextClustering\n",
    "\n",
    "\n",
    "text = [part for text in corpus.values() for part in text]\n",
    "wa_labels = [k for k, v in corpus.items() for _ in range(len(v))]\n",
    "\n",
    "# we set batch to false, because we already batched the data\n",
    "clustering = TextClustering()\n",
    "clustering(text=text, k=200, labels=wa_labels, batch=False, method=\"tSNE\")\n",
    "plt.legend(title=\"author\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Distinct authors in the WhatsApp dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from wa_analysis.data_analysis.model import TextClustering\n",
    "\n",
    "text = [part for text in corpus.values() for part in text]\n",
    "wa_labels = [k for k, v in corpus.items() for _ in range(len(v))]\n",
    "\n",
    "# Custom Palette\n",
    "unique_labels = list(set(wa_labels))\n",
    "custom_palette = {label: 'red' if label == 'motley-fox' else 'silver' for label in unique_labels}\n",
    "\n",
    "clustering = TextClustering()\n",
    "\n",
    "# Vervang de plot methode in de klasse\n",
    "def plot(self, X: np.ndarray, labels: list) -> None:\n",
    "    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=labels, palette=custom_palette, edgecolor='white', linewidth=0.8)\n",
    "\n",
    "# we set batch to false, because we already batched the data\n",
    "clustering.plot = plot.__get__(clustering, TextClustering)  \n",
    "clustering(text=text, k=200, labels=wa_labels, batch=False, method=\"tSNE\")\n",
    "\n",
    "# Vervang de kleuren\n",
    "scatter = plt.gca().collections[0]\n",
    "scatter.set_edgecolor('white')\n",
    "scatter.set_linewidth(0.5)\n",
    "\n",
    "# Outliers\n",
    "rect = patches.Rectangle((-33, -40), 27, 20, linewidth=2, edgecolor='silver', facecolor='none', linestyle='--')\n",
    "plt.gca().add_patch(rect)\n",
    "plt.annotate('Voornamelijk inhoud over het verzamelen', xy=(0, -35), xytext=(-33, -19),\n",
    "             fontsize=9, color='silver')\n",
    "\n",
    "\n",
    "plt.legend(title=\"Auteur\", bbox_to_anchor=(1.05, 1), loc=\"upper left\", \n",
    "           title_fontproperties={'weight': 'bold'})\n",
    "\n",
    "# plt.xticks([])\n",
    "# plt.legend().remove()\n",
    "# plt.yticks([])\n",
    "plt.suptitle(\"De coach communiceert duidelijk anders dan de rest\", fontsize = 16, fontweight = \"bold\")\n",
    "plt.title(\"en bemoeit zich al helemaal niet met het verzamelen...\")\n",
    "plt.figtext(0.0, -0.05, \"Gebaseerd op de top 10 bijdragers aan de WhatsApp groepchat (op basis van aantal berichten).\\n Bij het verzamelen wordt meestal één bericht gemaakt, waar de spelers hun eigen naam in zetten en versturen...\", wrap=True, horizontalalignment='left', fontsize=10)\n",
    "plt.show()\n",
    "plt.savefig(\"clustering.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_data = scatter.get_offsets()\n",
    "x_coords = scatter_data[:, 0]\n",
    "y_coords = scatter_data[:, 1]\n",
    "\n",
    "# Filter de berichten die in de outlier box vallen\n",
    "outlier_indices = []\n",
    "for i, (x, y) in enumerate(zip(x_coords, y_coords)):\n",
    "    if -33 <= x <= -6 and -40 <= y <= -20:  # Gebruik de coördinaten van je box\n",
    "        outlier_indices.append(i)\n",
    "\n",
    "# Bekijk de berichten\n",
    "outlier_messages = [text[i] for i in outlier_indices]\n",
    "outlier_authors = [wa_labels[i] for i in outlier_indices]\n",
    "\n",
    "# Eventueel opslaan in een CSV\n",
    "import pandas as pd\n",
    "outlier_df = pd.DataFrame({\n",
    "    'auteur': outlier_authors,\n",
    "    'bericht': outlier_messages,\n",
    "    'x': [x_coords[i] for i in outlier_indices],\n",
    "    'y': [y_coords[i] for i in outlier_indices]\n",
    "})\n",
    "outlier_df.to_csv('outlier_berichten.csv', index=False)\n",
    "print(\"Outlier berichten opgeslagen in outlier_berichten.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
